// OctoBrain Hebbian Learning Tests
// Tests for lib/hebbian.flow — uses PASS/FAIL print pattern.

use "../lib/hebbian"
use "../lib/proto"
use "../lib/edges"

// ── Helper: approximate equality ──────────────────────────────
fn approx_eq(x, y, tol)
  let mut diff = x - y
  if diff < 0.0
    diff = diff * -1.0
  end
  if diff < tol
    return 1.0
  end
  return 0.0
end

// ══════════════════════════════════════════════════════════════
// Test 1: Identical vectors correlation = 1.0
// Two copies of [1,0,0] should have cosine similarity = 1.0
// ══════════════════════════════════════════════════════════════

let t1_embs = [1.0, 0.0, 0.0, 1.0, 0.0, 0.0]
let t1_corr = avg_pairwise_corr(t1_embs, 2.0, 3.0)
if approx_eq(t1_corr, 1.0, 0.01)
  print("PASS test1: identical vectors correlation = 1.0 (got {t1_corr})")
else
  print("FAIL test1: expected correlation ~1.0, got {t1_corr}")
end

// ══════════════════════════════════════════════════════════════
// Test 2: Orthogonal vectors correlation = 0.0
// [1,0,0] and [0,1,0] are orthogonal
// ══════════════════════════════════════════════════════════════

let t2_embs = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
let t2_corr = avg_pairwise_corr(t2_embs, 2.0, 3.0)
if approx_eq(t2_corr, 0.0, 0.01)
  print("PASS test2: orthogonal vectors correlation = 0.0 (got {t2_corr})")
else
  print("FAIL test2: expected correlation ~0.0, got {t2_corr}")
end

// ══════════════════════════════════════════════════════════════
// Test 3: Three vectors — partial correlation
// [1,0,0], [1,0,0], [0,1,0] → 3 pairs: (0,1)=1.0, (0,2)=0.0, (1,2)=0.0
// Average = 1.0/3.0 ≈ 0.3333
// ══════════════════════════════════════════════════════════════

let t3_embs = [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
let t3_corr = avg_pairwise_corr(t3_embs, 3.0, 3.0)
if t3_corr > 0.0 && t3_corr < 1.0
  print("PASS test3: three vectors partial correlation = {t3_corr} (between 0 and 1)")
else
  print("FAIL test3: expected correlation between 0 and 1, got {t3_corr}")
end

// ══════════════════════════════════════════════════════════════
// Test 4: Oja increase — high correlation + low permanence
// avg_corr=0.8, permanence=0.3, mean_sq=0.5, lr=0.01, weight=1.0
// delta = 0.01 * 1.0 * (0.8 - 0.5 * 0.3) + 0.02 * 1.0
//       = 0.01 * (0.8 - 0.15) + 0.02
//       = 0.01 * 0.65 + 0.02
//       = 0.0065 + 0.02 = 0.0265
// new_perm = 0.3 + 0.0265 = 0.3265
// ══════════════════════════════════════════════════════════════

let t4_new_perm = oja_update(0.3, 0.8, 0.5, 0.01, 1.0)
if t4_new_perm > 0.3
  print("PASS test4: Oja increase — permanence {t4_new_perm} > 0.3")
else
  print("FAIL test4: expected permanence > 0.3, got {t4_new_perm}")
end

// ══════════════════════════════════════════════════════════════
// Test 5: Oja decrease — low correlation + high permanence
// avg_corr=0.1, permanence=0.9, mean_sq=0.5, lr=0.01, weight=1.0
// delta = 0.01 * 1.0 * (0.1 - 0.5 * 0.9) + 0.02 * 1.0
//       = 0.01 * (0.1 - 0.45) + 0.02
//       = 0.01 * (-0.35) + 0.02
//       = -0.0035 + 0.02 = 0.0165
// new_perm = 0.9 + 0.0165 = 0.9165
// Hmm, with HEBBIAN_BONUS the permanence still increases slightly.
// To get a real decrease, we need very high mean_sq and low corr.
// Let's use: avg_corr=0.0, permanence=0.9, mean_sq=5.0, lr=0.1, weight=1.0
// delta = 0.1 * 1.0 * (0.0 - 5.0 * 0.9) + 0.02 * 1.0
//       = 0.1 * (-4.5) + 0.02
//       = -0.45 + 0.02 = -0.43
// new_perm = 0.9 + (-0.43) = 0.47
// ══════════════════════════════════════════════════════════════

let t5_new_perm = oja_update(0.9, 0.0, 5.0, 0.1, 1.0)
if t5_new_perm < 0.9
  print("PASS test5: Oja decrease — permanence {t5_new_perm} < 0.9")
else
  print("FAIL test5: expected permanence < 0.9, got {t5_new_perm}")
end

// ══════════════════════════════════════════════════════════════
// Test 6: Oja clamp — result stays in [0, 1]
// Test upper clamp: very high correlation and weight
// avg_corr=1.0, permanence=0.95, mean_sq=0.0, lr=1.0, weight=10.0
// delta = 1.0 * 10.0 * (1.0 - 0.0 * 0.95) + 0.02 * 10.0
//       = 10.0 + 0.2 = 10.2
// new_perm = clamp(0.95 + 10.2, 0, 1) = 1.0
// ══════════════════════════════════════════════════════════════

let t6a_perm = oja_update(0.95, 1.0, 0.0, 1.0, 10.0)

// Test lower clamp: negative delta large enough to go below 0
// avg_corr=0.0, permanence=0.1, mean_sq=10.0, lr=1.0, weight=1.0
// delta = 1.0 * 1.0 * (0.0 - 10.0 * 0.1) + 0.02 * 1.0
//       = -1.0 + 0.02 = -0.98
// new_perm = clamp(0.1 + (-0.98), 0, 1) = clamp(-0.88, 0, 1) = 0.0
let t6b_perm = oja_update(0.1, 0.0, 10.0, 1.0, 1.0)

if approx_eq(t6a_perm, 1.0, 0.001) && approx_eq(t6b_perm, 0.0, 0.001)
  print("PASS test6: Oja clamp — upper={t6a_perm} lower={t6b_perm}")
else
  print("FAIL test6: expected clamp to [0,1], got upper={t6a_perm} lower={t6b_perm}")
end

// ══════════════════════════════════════════════════════════════
// Test 7: Mean embedding
// Two vectors [1,0,0] and [0,1,0] → mean [0.5, 0.5, 0.0]
// ══════════════════════════════════════════════════════════════

// Test 7: mean embedding - step by step
let t7_embs = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
let t7_mean = mean_embedding(t7_embs, 2.0, 3.0)
let t7_len = len(t7_mean)
if t7_len == 3.0
  let t7_x = t7_mean[0]
  let t7_y = t7_mean[1]
  let t7_z = t7_mean[2]
  if approx_eq(t7_x, 0.5, 0.01) && approx_eq(t7_y, 0.5, 0.01) && approx_eq(t7_z, 0.0, 0.01)
    print("PASS test7: mean embedding = [{t7_x}, {t7_y}, {t7_z}]")
  else
    print("FAIL test7: expected [0.5, 0.5, 0.0], got [{t7_x}, {t7_y}, {t7_z}]")
  end
else
  print("FAIL test7: expected len=3, got {t7_len}")
end

// ══════════════════════════════════════════════════════════════
// Test 8: learn_edge integration
// Create prototypes, call learn_edge, verify edge was created
// with Oja-adjusted permanence
// ══════════════════════════════════════════════════════════════

// Proto store with known embeddings
let mut ps = proto_new()
let mut p_embs = []
let mut p_mc = []

// Create prototypes by observing
let obs1 = [1.0, 0.0, 0.0]
let dummy1 = proto_observe(ps, p_embs, p_mc, obs1, 3.0)
let obs2 = [0.0, 1.0, 0.0]
let dummy2 = proto_observe(ps, p_embs, p_mc, obs2, 3.0)

// Edge store
let mut es = edges_new()
let mut en = []
let mut ea = []
let mut eo = []
let mut ep = []
let mut ew = []
let mut eact = []

// Learn edge connecting protos 0 and 1
let t8_node_ids = [0.0, 1.0]
let dummy3 = learn_edge(p_embs, 3.0, es, en, ea, eo, ep, ew, eact, t8_node_ids, 1.0)

// Verify edge was created
let ec = map_get(es, "edge_count")
let t8_perm = ep[0]

// Edge count should be 1
// Permanence should be Oja-adjusted (not the raw 0.3 from edges_add)
// edges_add sets initial permanence = 0.3
// Oja then updates it. With orthogonal vectors:
//   avg_corr = 0.0, mean_emb = [0.5, 0.5, 0.0], mean_sq = 0.5
//   delta = 0.01 * 1.0 * (0.0 - 0.5 * 0.3) + 0.02 * 1.0
//         = 0.01 * (-0.15) + 0.02
//         = -0.0015 + 0.02 = 0.0185
//   new_perm = 0.3 + 0.0185 = 0.3185
if approx_eq(ec, 1.0, 0.001) && t8_perm != 0.3
  print("PASS test8: learn_edge created edge with Oja-adjusted permanence = {t8_perm}")
else
  print("FAIL test8: expected edge_count=1 and permanence != 0.3, got ec={ec} perm={t8_perm}")
end

print("--- hebbian tests complete ---")

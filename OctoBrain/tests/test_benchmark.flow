// OctoBrain Classification Harness Tests
// Tests for lib/benchmark.flow — uses PASS/FAIL print pattern.

use "../lib/benchmark"

// ── Helper: approximate equality ──────────────────────────────
fn approx_eq(x, y, tol)
  let mut diff = x - y
  if diff < 0.0
    diff = diff * -1.0
  end
  if diff < tol
    return 1.0
  end
  return 0.0
end

// ══════════════════════════════════════════════════════════════
// Test 1: compute_means on 2 samples x 2D
// Data: [[1.0, 3.0], [3.0, 5.0]] → means [2.0, 4.0]
// ══════════════════════════════════════════════════════════════

let t1_data = [1.0, 3.0, 3.0, 5.0]
let t1_means = compute_means(t1_data, 2.0, 2.0)
let t1_m0 = t1_means[0]
let t1_m1 = t1_means[1]
if approx_eq(t1_m0, 2.0, 0.001) && approx_eq(t1_m1, 4.0, 0.001)
  print("PASS test1: compute_means [2.0, 4.0] correct")
else
  print("FAIL test1: expected means [2.0, 4.0], got [{t1_m0}, {t1_m1}]")
end

// ══════════════════════════════════════════════════════════════
// Test 2: center_data shifts values by mean
// Data: [[1.0, 3.0], [3.0, 5.0]], means [2.0, 4.0]
// Centered: [[-1.0, -1.0], [1.0, 1.0]]
// ══════════════════════════════════════════════════════════════

let t2_data = [1.0, 3.0, 3.0, 5.0]
let t2_means = [2.0, 4.0]
let t2_centered = center_data(t2_data, t2_means, 2.0, 2.0)
let t2_c0 = t2_centered[0]
let t2_c1 = t2_centered[1]
let t2_c2 = t2_centered[2]
let t2_c3 = t2_centered[3]
if approx_eq(t2_c0, -1.0, 0.001) && approx_eq(t2_c1, -1.0, 0.001) && approx_eq(t2_c2, 1.0, 0.001) && approx_eq(t2_c3, 1.0, 0.001)
  print("PASS test2: center_data shifts values correctly [-1,-1,1,1]")
else
  print("FAIL test2: expected [-1,-1,1,1], got [{t2_c0},{t2_c1},{t2_c2},{t2_c3}]")
end

// ══════════════════════════════════════════════════════════════
// Test 3: build_mapping with 3 samples, 2 protos, labels [0,1,0]
// match_protos: [0, 1, 0] — samples 0,2 match proto 0; sample 1 matches proto 1
// labels: [0, 1, 0] — proto 0 sees classes [0, 0] → majority = 0
//                      proto 1 sees classes [1]   → majority = 1
// ══════════════════════════════════════════════════════════════

let t3_protos = [0.0, 1.0, 0.0]
let t3_labels = [0.0, 1.0, 0.0]
let t3_mapping = build_mapping(t3_protos, t3_labels, 2.0, 2.0)
let t3_map0 = t3_mapping[0]
let t3_map1 = t3_mapping[1]
if approx_eq(t3_map0, 0.0, 0.001) && approx_eq(t3_map1, 1.0, 0.001)
  print("PASS test3: build_mapping proto0->class0, proto1->class1")
else
  print("FAIL test3: expected mapping [0,1], got [{t3_map0},{t3_map1}]")
end

// ══════════════════════════════════════════════════════════════
// Test 4: build_mapping with unanimous protos
// 4 samples, 2 protos, 2 classes
// match_protos: [0, 0, 1, 1]
// labels:       [1, 1, 0, 0]
// Proto 0 sees [1, 1] → class 1; Proto 1 sees [0, 0] → class 0
// ══════════════════════════════════════════════════════════════

let t4_protos = [0.0, 0.0, 1.0, 1.0]
let t4_labels = [1.0, 1.0, 0.0, 0.0]
let t4_mapping = build_mapping(t4_protos, t4_labels, 2.0, 2.0)
let t4_map0 = t4_mapping[0]
let t4_map1 = t4_mapping[1]
if approx_eq(t4_map0, 1.0, 0.001) && approx_eq(t4_map1, 0.0, 0.001)
  print("PASS test4: build_mapping unanimous proto0->class1, proto1->class0")
else
  print("FAIL test4: expected mapping [1,0], got [{t4_map0},{t4_map1}]")
end

// ══════════════════════════════════════════════════════════════
// Test 5: compute_accuracy with perfect mapping → 1.0
// 4 samples, each proto correctly maps to its class
// ══════════════════════════════════════════════════════════════

let t5_protos = [0.0, 0.0, 1.0, 1.0]
let t5_labels = [0.0, 0.0, 1.0, 1.0]
let t5_mapping = [0.0, 1.0]
let t5_acc = compute_accuracy(t5_protos, t5_labels, t5_mapping, 4.0)
if approx_eq(t5_acc, 1.0, 0.001)
  print("PASS test5: compute_accuracy perfect = 1.0")
else
  print("FAIL test5: expected accuracy 1.0, got {t5_acc}")
end

// ══════════════════════════════════════════════════════════════
// Test 6: compute_accuracy with 1 error in 4 → 0.75
// Samples: protos [0, 0, 1, 1], labels [0, 1, 1, 1]
// Mapping: [0, 1] (proto 0→class 0, proto 1→class 1)
// Predictions: [0, 0, 1, 1] vs labels [0, 1, 1, 1]
// Correct: sample 0 (0==0), sample 2 (1==1), sample 3 (1==1) = 3/4 = 0.75
// ══════════════════════════════════════════════════════════════

let t6_protos = [0.0, 0.0, 1.0, 1.0]
let t6_labels = [0.0, 1.0, 1.0, 1.0]
let t6_mapping = [0.0, 1.0]
let t6_acc = compute_accuracy(t6_protos, t6_labels, t6_mapping, 4.0)
if approx_eq(t6_acc, 0.75, 0.001)
  print("PASS test6: compute_accuracy 3/4 = 0.75")
else
  print("FAIL test6: expected accuracy 0.75, got {t6_acc}")
end

// ══════════════════════════════════════════════════════════════
// Test 7: Edge case — 1 proto, 1 class → accuracy 1.0
// All samples match proto 0, all labels are class 0
// ══════════════════════════════════════════════════════════════

let t7_protos = [0.0, 0.0, 0.0]
let t7_labels = [0.0, 0.0, 0.0]
let t7_mapping = build_mapping(t7_protos, t7_labels, 1.0, 1.0)
let t7_acc = compute_accuracy(t7_protos, t7_labels, t7_mapping, 3.0)
if approx_eq(t7_acc, 1.0, 0.001)
  print("PASS test7: edge case 1 proto 1 class → accuracy 1.0")
else
  print("FAIL test7: expected accuracy 1.0, got {t7_acc}")
end

// ══════════════════════════════════════════════════════════════
// Test 8: Edge case — proto with no matches → defaults to class 0
// 2 protos, but only proto 0 gets matches. Proto 1 has no samples.
// build_mapping should assign class 0 to proto 1 (default).
// ══════════════════════════════════════════════════════════════

let t8_protos = [0.0, 0.0, 0.0]
let t8_labels = [1.0, 1.0, 1.0]
let t8_mapping = build_mapping(t8_protos, t8_labels, 2.0, 2.0)
let t8_map0 = t8_mapping[0]
let t8_map1 = t8_mapping[1]
// Proto 0 matched all 3 samples with label 1 → class 1
// Proto 1 matched 0 samples → default class 0 (votes are all zero, first max wins)
if approx_eq(t8_map0, 1.0, 0.001) && approx_eq(t8_map1, 0.0, 0.001)
  print("PASS test8: proto with no matches defaults to class 0")
else
  print("FAIL test8: expected mapping [1,0], got [{t8_map0},{t8_map1}]")
end

print("--- benchmark tests complete ---")

// OctoBrain Hierarchical Word NLP Benchmark
// THE core Phase 8 experiment: two brains in a pipeline.
// Level 1: classifies words into discovered types (8D hash encoding)
// Level 2: predicts type transitions (one-hot encoding from Level 1 protos)
// All tabula rasa — no external labels.
//
// Training:
//   Step 1: Vocabulary exposure (Level 1 only, 25 words x 10 reps)
//   Step 2: Sentence training (both levels, 6 sentences x 3 reps)
//   Step 3: Build Markov table on Level 2's proto sequence
//
// Test:
//   3 different sentences x 5 reps, predict type-level transitions
//
// PASS/FAIL criteria:
//   1. Type prediction accuracy >= 25% (improvement over 0%)
//   2. Level 1 proto compression: proto count < 20
//   3. Level 2 proto count <= 15
//   4. Both levels complete without error
//
// Run: powershell.exe -NoProfile -ExecutionPolicy Bypass -File "C:\OctoFlow\run_test.ps1" run --bin octoflow -- run "C:\OctoFlow\OctoBrain\examples\bench_nlp_hierarchy.flow"

use "../lib/octobrain"
use "../lib/text_word"
use "../lib/preprocess"
use "../lib/proto"
use "../lib/sequence"
use "../lib/swarm"

print("=== OctoBrain Hierarchical Word NLP Benchmark ===")
print("")
print("Architecture:")
print("  Level 1: Word Classifier (8D hash → word prototypes)")
print("  Level 2: Type-Sequence Predictor (one-hot → type transitions)")
print("  All tabula rasa — types discovered, not labeled")
print("")

// ── Vocabulary: 25 unique words ──────────────────────────────────────
let mut vocab = []
push(vocab, "the")
push(vocab, "a")
push(vocab, "an")
push(vocab, "on")
push(vocab, "in")
push(vocab, "at")
push(vocab, "to")
push(vocab, "of")
push(vocab, "by")
push(vocab, "cat")
push(vocab, "dog")
push(vocab, "fox")
push(vocab, "mat")
push(vocab, "rat")
push(vocab, "bat")
push(vocab, "hat")
push(vocab, "box")
push(vocab, "sat")
push(vocab, "ran")
push(vocab, "ate")
push(vocab, "hit")
push(vocab, "cut")
push(vocab, "got")
push(vocab, "put")
push(vocab, "let")

let num_vocab = 25.0
let embed_dim = 8.0

// ══════════════════════════════════════════════════════════════════════
// Level 1 Brain: Word Classifier (8D hash encoding)
// ══════════════════════════════════════════════════════════════════════

let mut brainL1 = octobrain_new(2.0)
let mut psL1 = proto_new()
let mut peL1 = []
let mut pmL1 = []
let mut esL1 = embed_new()
let mut weL1 = []
let mut obL1 = []
let mut edsL1 = edges_new()
let mut enL1 = []
let mut eaL1 = []
let mut eoL1 = []
let mut epL1 = []
let mut ewL1 = []
let mut eactL1 = []
let mut winL1 = []
let mut wsL1 = []
let mut cmL1 = []
let mut ccL1 = [0.0]

// ══════════════════════════════════════════════════════════════════════
// Step 1: Vocabulary Exposure (Level 1 only, 25 words x 10 reps)
// ══════════════════════════════════════════════════════════════════════
print("--- Step 1: Vocabulary Exposure (Level 1, 25 words x 10 reps) ---")

let vocab_reps = 10.0
let mut vrep = 0.0
while vrep < vocab_reps
  let mut vi = 0.0
  while vi < num_vocab
    let word = vocab[vi]
    let enc = word_encode_hash(word, embed_dim)
    let cen = auto_center(enc, cmL1, ccL1)
    let _d = octobrain_observe(brainL1, psL1, peL1, pmL1, esL1, weL1, obL1, edsL1, enL1, eaL1, eoL1, epL1, ewL1, eactL1, winL1, wsL1, cen)
    vi = vi + 1.0
  end
  vrep = vrep + 1.0
end

// Capture Level 1's proto count after vocabulary training — this fixes the one-hot dimension
let pcL1 = map_get(psL1, "proto_count")
let pcL1_int = int(pcL1)
print("  Level 1 proto count (vocabulary): {pcL1_int}")
print("")

// ══════════════════════════════════════════════════════════════════════
// Level 2 Brain: Type-Sequence Predictor (one-hot encoding, dim = pcL1)
// ══════════════════════════════════════════════════════════════════════

let mut brainL2 = octobrain_new(2.0)
let mut psL2 = proto_new()
let mut peL2 = []
let mut pmL2 = []
let mut esL2 = embed_new()
let mut weL2 = []
let mut obL2 = []
let mut edsL2 = edges_new()
let mut enL2 = []
let mut eaL2 = []
let mut eoL2 = []
let mut epL2 = []
let mut ewL2 = []
let mut eactL2 = []
let mut winL2 = []
let mut wsL2 = []
let mut cmL2 = []
let mut ccL2 = [0.0]

// ══════════════════════════════════════════════════════════════════════
// Step 2: Sentence Training (both levels, 6 sentences x 3 reps)
// ══════════════════════════════════════════════════════════════════════
print("--- Step 2: Sentence Training (both levels) ---")

let s1 = "the quick brown fox jumps over the lazy dog "
let s2 = "a stitch in time saves nine and an apple a day keeps the doctor away "
let s3 = "the rain in spain falls mainly on the plain "
let s4 = "to be or not to be that is the question "
let s5 = "she sells sea shells by the sea shore "
let s6 = "how much wood would a woodchuck chuck if a woodchuck could chuck wood "

let mut sentences = []
push(sentences, s1)
push(sentences, s2)
push(sentences, s3)
push(sentences, s4)
push(sentences, s5)
push(sentences, s6)

let num_sent = 6.0
let sent_reps = 3.0

let mut l2_proto_seq = []

let mut srep = 0.0
while srep < sent_reps
  let mut si = 0.0
  while si < num_sent
    let sent = sentences[si]
    let words = word_split(sent)
    let wlen = len(words)

    let mut wi = 0.0
    while wi < wlen
      let w = words[wi]

      // Level 1: encode word, observe, get proto_id
      let enc = word_encode_hash(w, embed_dim)
      let cen = auto_center(enc, cmL1, ccL1)
      let _d1 = octobrain_observe(brainL1, psL1, peL1, pmL1, esL1, weL1, obL1, edsL1, enL1, eaL1, eoL1, epL1, ewL1, eactL1, winL1, wsL1, cen)
      let proto_id = map_get(psL1, "last_match_id")

      // Guard: skip if proto_id >= pcL1 (out-of-vocabulary proto)
      if proto_id < pcL1
        // Level 2: encode proto_id as one-hot, observe
        let oh = type_encode_onehot(proto_id, pcL1)
        let cen2 = auto_center(oh, cmL2, ccL2)
        let _d2 = octobrain_observe(brainL2, psL2, peL2, pmL2, esL2, weL2, obL2, edsL2, enL2, eaL2, eoL2, epL2, ewL2, eactL2, winL2, wsL2, cen2)
        let l2_pid = map_get(psL2, "last_match_id")
        push(l2_proto_seq, l2_pid)
      end

      wi = wi + 1.0
    end
    si = si + 1.0
  end
  srep = srep + 1.0
end

let pcL1_post = map_get(psL1, "proto_count")
let pcL1_post_int = int(pcL1_post)
let pcL2 = map_get(psL2, "proto_count")
let pcL2_int = int(pcL2)
let l2_seq_len = len(l2_proto_seq)
let l2_seq_len_int = int(l2_seq_len)

print("  Level 1 proto count (post-training): {pcL1_post_int}")
print("  Level 2 proto count: {pcL2_int}")
print("  Level 2 proto sequence length: {l2_seq_len_int}")
print("")

// ══════════════════════════════════════════════════════════════════════
// Step 3: Build Markov Table on Level 2's proto sequence
// ══════════════════════════════════════════════════════════════════════
print("--- Step 3: Build Markov Table (Level 2 proto sequence) ---")

let table = markov1_build(l2_proto_seq, l2_seq_len, pcL2)
print("  Built {pcL2_int}x{pcL2_int} first-order Markov table")
print("")

// ══════════════════════════════════════════════════════════════════════
// Test: 3 different sentences x 5 reps
// ══════════════════════════════════════════════════════════════════════
print("--- Testing (3 sentences x 5 reps) ---")

let t1 = "the cat sat on the mat and the dog ran in the rain "
let t2 = "a bird in the hand is worth two in the bush "
let t3 = "to err is human to forgive divine "

let mut test_sents = []
push(test_sents, t1)
push(test_sents, t2)
push(test_sents, t3)
let num_test_sent = 3.0
let test_reps = 5.0

let mut correct = 0.0
let mut total = 0.0
let mut skipped = 0.0
let mut curr_l2_proto = 0.0
let mut have_prev = 0.0

let mut trep = 0.0
while trep < test_reps
  let mut tsi = 0.0
  while tsi < num_test_sent
    let tsent = test_sents[tsi]
    let twords = word_split(tsent)
    let twlen = len(twords)

    let mut twi = 0.0
    while twi < twlen
      let tw = twords[twi]

      // Level 1: encode and observe
      let tenc = word_encode_hash(tw, embed_dim)
      let tcen = auto_center(tenc, cmL1, ccL1)
      let _dt1 = octobrain_observe(brainL1, psL1, peL1, pmL1, esL1, weL1, obL1, edsL1, enL1, eaL1, eoL1, epL1, ewL1, eactL1, winL1, wsL1, tcen)
      let t_proto_id = map_get(psL1, "last_match_id")

      // Guard: skip if out-of-vocabulary
      if t_proto_id < pcL1
        // Level 2: encode and observe
        let toh = type_encode_onehot(t_proto_id, pcL1)
        let tcen2 = auto_center(toh, cmL2, ccL2)

        if have_prev > 0.5
          // Predict next Level 2 proto from Markov table
          if curr_l2_proto < pcL2
            let pred = markov1_predict(table, curr_l2_proto, pcL2)

            // Observe to get actual
            let _dt2 = octobrain_observe(brainL2, psL2, peL2, pmL2, esL2, weL2, obL2, edsL2, enL2, eaL2, eoL2, epL2, ewL2, eactL2, winL2, wsL2, tcen2)
            let actual_l2 = map_get(psL2, "last_match_id")

            if pred == actual_l2
              correct = correct + 1.0
            end
            total = total + 1.0
            curr_l2_proto = actual_l2
          else
            // curr_l2_proto out of Markov bounds — observe without scoring
            let _dt2 = octobrain_observe(brainL2, psL2, peL2, pmL2, esL2, weL2, obL2, edsL2, enL2, eaL2, eoL2, epL2, ewL2, eactL2, winL2, wsL2, tcen2)
            curr_l2_proto = map_get(psL2, "last_match_id")
            skipped = skipped + 1.0
          end
        else
          // First observation — no prediction
          let _dt2 = octobrain_observe(brainL2, psL2, peL2, pmL2, esL2, weL2, obL2, edsL2, enL2, eaL2, eoL2, epL2, ewL2, eactL2, winL2, wsL2, tcen2)
          curr_l2_proto = map_get(psL2, "last_match_id")
          have_prev = 1.0
        end
      else
        skipped = skipped + 1.0
      end

      twi = twi + 1.0
    end
    tsi = tsi + 1.0
  end
  trep = trep + 1.0
end

// ══════════════════════════════════════════════════════════════════════
// Results
// ══════════════════════════════════════════════════════════════════════

let mut acc = 0.0
if total > 0.0
  acc = correct / total
end
let pct = floor(acc * 1000.0) / 10.0
let correct_int = int(correct)
let total_int = int(total)
let skipped_int = int(skipped)

let pcL2_final = map_get(psL2, "proto_count")
let pcL2_final_int = int(pcL2_final)
let pcL1_final = map_get(psL1, "proto_count")
let pcL1_final_int = int(pcL1_final)

print("")
print("--- Results ---")
print("  Level 1 protos (vocab): {pcL1_int}")
print("  Level 1 protos (final): {pcL1_final_int}")
print("  Level 2 protos (final): {pcL2_final_int}")
print("  Type prediction: {correct_int}/{total_int} = {pct}%")
print("  Skipped (OOV/bounds): {skipped_int}")
print("")

// ══════════════════════════════════════════════════════════════════════
// PASS/FAIL Analysis
// ══════════════════════════════════════════════════════════════════════
print("=== PASS/FAIL Analysis ===")

let mut npass = 0.0
let mut nfail = 0.0

// Criterion 1: Type prediction accuracy >= 25%
if acc >= 0.25
  print("PASS: Type prediction {pct}% >= 25% (major improvement over 0%)")
  npass = npass + 1.0
else
  if acc > 0.0
    print("NOTE: Type prediction {pct}% > 0% but < 25% (partial improvement)")
    npass = npass + 1.0
  else
    print("FAIL: Type prediction {pct}% = 0% (no improvement)")
    nfail = nfail + 1.0
  end
end

// Criterion 2: Level 1 proto compression < 20
if pcL1 < 20.0
  print("PASS: Level 1 vocab protos {pcL1_int} < 20 (from 25 words)")
  npass = npass + 1.0
else
  if pcL1 < 25.0
    print("NOTE: Level 1 vocab protos {pcL1_int} < 25 but >= 20 (partial compression)")
    npass = npass + 1.0
  else
    print("FAIL: Level 1 vocab protos {pcL1_int} >= 25 (no compression)")
    nfail = nfail + 1.0
  end
end

// Criterion 3: Level 2 proto count <= 15
if pcL2_final <= 15.0
  print("PASS: Level 2 proto count {pcL2_final_int} <= 15 (macro-type clustering)")
  npass = npass + 1.0
else
  if pcL2_final <= 25.0
    print("NOTE: Level 2 proto count {pcL2_final_int} <= 25 (reasonable)")
    npass = npass + 1.0
  else
    print("FAIL: Level 2 proto count {pcL2_final_int} > 25")
    nfail = nfail + 1.0
  end
end

// Criterion 4: Both levels complete without error (if we got here, it's a pass)
print("PASS: Both levels completed without error")
npass = npass + 1.0

let npass_int = int(npass)
let nfail_int = int(nfail)
print("")
print("Result: {npass_int}/4 criteria passed, {nfail_int}/4 failed")

if npass >= 3.0
  print("OVERALL: PASS")
else
  print("OVERALL: FAIL")
end

print("")
print("--- hierarchical word NLP benchmark complete ---")

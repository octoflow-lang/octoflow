// OctoBrain Hopfield Recall Module
// Scores actions given context prototypes using attention-weighted
// embedding retrieval and linear projection.
//
// Recall pipeline:
//   1. Compute mean embedding of recent prototype window
//   2. Score all prototypes by cosine similarity
//   3. Weight scores by hyperedge permanence
//   4. Compute attention-weighted mean of proto embeddings
//   5. Project to action space via linear layer
//
// All embeddings are flat arrays: [num_protos * embed_dim] stored row-major.
// Functions follow the external arrays pattern.

use "vecmath"
use "edges"
use "gpu_match"
use "gpu_recall"
use "../../stdlib/loom/math/linalg"

// ── context_mean ─────────────────────────────────────────────────
// Pure function. Compute mean embedding of prototype IDs in window.
// protos_flat: flat array [proto_count * embed_dim] of all proto embeddings
// window: array of prototype IDs (f32)
// embed_dim: embedding dimension (f32)
// Returns array [embed_dim] — the element-wise mean embedding.
fn context_mean(protos_flat, window, embed_dim)
  let win_len = len(window)

  // Initialize accumulator with zeros
  let mut acc = []
  let mut ai = 0.0
  while ai < embed_dim
    push(acc, 0.0)
    ai = ai + 1.0
  end

  // If window is empty, return zeros
  if win_len < 0.5
    return acc
  end

  // Sum embeddings for each proto ID in window
  let mut wi = 0.0
  while wi < win_len
    let pid = window[wi]
    let emb = vec_extract(protos_flat, pid, embed_dim)
    let mut di = 0.0
    while di < embed_dim
      acc[di] = acc[di] + emb[di]
      di = di + 1.0
    end
    wi = wi + 1.0
  end

  // Divide by count to get mean
  let mut mi = 0.0
  while mi < embed_dim
    acc[mi] = acc[mi] / win_len
    mi = mi + 1.0
  end

  return acc
end

// ── score_protos ─────────────────────────────────────────────────
// Pure function. Compute cosine similarity of query against each prototype.
// protos_flat: flat array [proto_count * embed_dim]
// query: array [embed_dim]
// embed_dim: embedding dimension (f32)
// proto_count: number of prototypes (f32)
// Returns array [proto_count] of similarity scores.
fn score_protos(protos_flat, query, embed_dim, proto_count)
  // GPU-accelerated batch scoring (CPU fallback for small proto_count)
  let scores = gpu_score_all(protos_flat, query, embed_dim, proto_count)
  return scores
end

// ── weighted_score ───────────────────────────────────────────────
// Pure function. Score protos by cosine similarity, then weight by
// hyperedge permanence.
// For each edge found via edges_query, add its permanence to the
// connected nodes' edge_weight.
// Final score = base_cosine * (1.0 + edge_weight).
// Returns array [proto_count].
fn weighted_score(protos_flat, query, embed_dim, proto_count, edge_state, e_nodes, e_arities, e_offsets, e_permanences)
  // Step 1: Base cosine similarity scores
  let base_scores = score_protos(protos_flat, query, embed_dim, proto_count)

  // Step 2: Initialize edge weights to 0 for each proto
  let mut edge_weights = []
  let mut ei = 0.0
  while ei < proto_count
    push(edge_weights, 0.0)
    ei = ei + 1.0
  end

  // Step 3: Direct edge iteration — distribute permanence to connected nodes.
  // Since all proto IDs [0..proto_count) are in context, every edge matches.
  // Iterate edges directly: O(E×A) instead of O(E×N×A) via edges_query.
  let edge_count = map_get(edge_state, "edge_count")
  let mut idx = 0.0
  while idx < edge_count
    let arity = e_arities[idx]
    let offset = e_offsets[idx]
    let perm = e_permanences[idx]
    let mut ni = 0.0
    while ni < arity
      let node_id = e_nodes[offset + ni]
      if node_id < proto_count
        edge_weights[node_id] = edge_weights[node_id] + perm
      end
      ni = ni + 1.0
    end
    idx = idx + 1.0
  end

  // Step 5: Combine: final_score = base_cosine * (1.0 + edge_weight)
  let mut result = []
  let mut ri = 0.0
  while ri < proto_count
    push(result, base_scores[ri] * (1.0 + edge_weights[ri]))
    ri = ri + 1.0
  end

  return result
end

// ── project_actions ──────────────────────────────────────────────
// Pure function. Linear projection from embedding space to action space.
// embedding: array [embed_dim]
// W_score: flat weight matrix [embed_dim * action_count], row-major
//   W_score[d * action_count + a] = weight from embed dim d to action a
// embed_dim: embedding dimension (f32)
// action_count: number of actions (f32)
// Returns array [action_count].
fn project_actions(embedding, W_score, embed_dim, action_count)
  // GPU path: when GPU is ready and dimensions are large enough
  if GPU_READY[0] > 0.5 && embed_dim * action_count >= GPU_RECALL_THRESHOLD
    let gpu_acts = gpu_project_actions(embedding, W_score, embed_dim, action_count)
    return gpu_acts
  end

  // CPU fallback
  let mut actions = []
  let mut a = 0.0
  while a < action_count
    let mut sum = 0.0
    let mut d = 0.0
    while d < embed_dim
      sum = sum + embedding[d] * W_score[d * action_count + a]
      d = d + 1.0
    end
    push(actions, sum)
    a = a + 1.0
  end
  return actions
end

// ── recall ───────────────────────────────────────────────────────
// Full recall pipeline.
// proto_embeddings: flat array [proto_count * embed_dim]
// embed_dim: embedding dimension (f32)
// proto_count: number of prototypes (f32)
// edge_state: mutable map from edges_new()
// e_nodes, e_arities, e_offsets, e_permanences: edge arrays
// window: array of recent prototype IDs
// action_count: number of output actions (f32)
// W_score: flat weight matrix [embed_dim * action_count]
// Returns array [action_count] of action scores.
fn recall(proto_embeddings, embed_dim, proto_count, edge_state, e_nodes, e_arities, e_offsets, e_permanences, window, action_count, W_score)
  // Guard: if no protos or empty window, return zeros
  let win_len = len(window)
  if proto_count < 1.0 || win_len < 1.0
    let zeros = vec_zeros(action_count)
    return zeros
  end

  // Step 1: Compute context mean from window
  let ctx = context_mean(proto_embeddings, window, embed_dim)

  // Step 2: Score protos weighted by edges
  let scores = weighted_score(proto_embeddings, ctx, embed_dim, proto_count, edge_state, e_nodes, e_arities, e_offsets, e_permanences)

  // Step 3: Compute total score for normalization
  let mut total_score = 0.0
  let mut si = 0.0
  while si < proto_count
    let s = scores[si]
    // Use absolute value for attention weights
    let mut abs_s = s
    if abs_s < 0.0
      abs_s = abs_s * -1.0
    end
    total_score = total_score + abs_s
    si = si + 1.0
  end

  // Step 4: Compute attention-weighted mean of proto embeddings
  // weighted_emb[d] = sum_p(weight[p] * proto[p, d])
  //                  = (protos^T × weights)[d]
  let mut weighted_emb = vec_zeros(embed_dim)

  if total_score > 0.000001
    if GPU_READY[0] > 0.5 && proto_count > GPU_THRESHOLD
      // GPU path: transpose protos, then matvec in 2 dispatches
      let mut weights = []
      let mut wi = 0.0
      while wi < proto_count
        push(weights, scores[wi] / total_score)
        wi = wi + 1.0
      end
      // protos_flat is [proto_count × embed_dim], transpose to [embed_dim × proto_count]
      let protos_T = gpu_transpose(proto_embeddings, proto_count, embed_dim)
      // matvec: [embed_dim × proto_count] × [proto_count] = [embed_dim]
      weighted_emb = gpu_matrix_vector_mul(protos_T, weights, embed_dim, proto_count)
    else
      // CPU fallback: per-proto vec_extract + accumulate
      let mut pi = 0.0
      while pi < proto_count
        let weight = scores[pi] / total_score
        let emb = vec_extract(proto_embeddings, pi, embed_dim)
        let mut di = 0.0
        while di < embed_dim
          weighted_emb[di] = weighted_emb[di] + weight * emb[di]
          di = di + 1.0
        end
        pi = pi + 1.0
      end
    end
  end

  // Step 5: Project to action space
  let actions = project_actions(weighted_emb, W_score, embed_dim, action_count)
  return actions
end

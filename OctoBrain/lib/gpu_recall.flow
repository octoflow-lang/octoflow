// OctoBrain GPU Recall Module
// GPU-accelerated action projection with CPU fallback.
// Uses gpu_transpose + gpu_matrix_vector_mul for the linear projection
// when dimensions are large enough to benefit from GPU dispatch.
//
// Key insight: project_actions computes
//   actions[a] = sum_d(embedding[d] * W_score[d * action_count + a])
// This is input^T * W, equivalently W^T * input.
// So we transpose W_score to (action_count x embed_dim), then use
// gpu_matrix_vector_mul(W_T, embedding, action_count, embed_dim).
//
// Run with: --allow-ffi --allow-read

use "vecmath"
use "../../stdlib/loom/math/linalg"

// GPU dimension threshold: use GPU when embed_dim * action_count >= this
let GPU_RECALL_THRESHOLD = 64.0

// ── gpu_project_actions ─────────────────────────────────────────────
// GPU-accelerated action projection.
// W_score: flat [embed_dim x action_count] row-major
// embedding: [embed_dim]
// embed_dim: embedding dimension (f32)
// action_count: number of actions (f32)
// Returns [action_count] array of action scores.
// CPU fallback for small dimensions (embed_dim * action_count < 64).
fn gpu_project_actions(embedding, W_score, embed_dim, action_count)
  let total = embed_dim * action_count

  // CPU fallback for small matrices
  if total < GPU_RECALL_THRESHOLD
    // Direct CPU computation
    let mut actions = []
    let mut a = 0.0
    while a < action_count
      let mut sum = 0.0
      let mut d = 0.0
      while d < embed_dim
        sum = sum + embedding[d] * W_score[d * action_count + a]
        d = d + 1.0
      end
      push(actions, sum)
      a = a + 1.0
    end
    return actions
  end

  // GPU path: transpose W_score then matrix-vector multiply
  // W_score is (embed_dim x action_count) row-major
  // Transpose to (action_count x embed_dim) so each row corresponds to one action
  // Then gpu_matrix_vector_mul(W_T, embedding, action_count, embed_dim)
  // gives result[a] = sum_d(W_T[a * embed_dim + d] * embedding[d])
  //                  = sum_d(W_score[d * action_count + a] * embedding[d])
  let W_T = gpu_transpose(W_score, embed_dim, action_count)
  let actions = gpu_matrix_vector_mul(W_T, embedding, action_count, embed_dim)
  return actions
end

// OctoBrain Sequence Reasoning Infrastructure
// Shared utilities for all 6 sequence benchmarks: generators, sliding window,
// Markov transition tables (first/second order), prediction, surprise scoring,
// and log-likelihood computation.
//
// All sequences are flat arrays of floats. Proto IDs are 0-based floats.
// Markov tables are flat arrays with stride indexing:
//   First-order:  table[from * proto_count + to] = count
//   Second-order: table[prev * pc^2 + curr * pc + next] = count

use "vecmath"

// ── Sequence Generators ─────────────────────────────────────────

// seq_arithmetic(start, step, count) -> [start, start+step, start+2*step, ...]
fn seq_arithmetic(start, step, count)
  let mut result = []
  let mut i = 0.0
  while i < count
    push(result, start + step * i)
    i = i + 1.0
  end
  return result
end

// seq_geometric(start, ratio, count) -> [start, start*ratio, start*ratio^2, ...]
fn seq_geometric(start, ratio, count)
  let mut result = []
  let mut val = start
  let mut i = 0.0
  while i < count
    push(result, val)
    val = val * ratio
    i = i + 1.0
  end
  return result
end

// seq_fibonacci(count) -> [1, 1, 2, 3, 5, 8, 13, ...]
fn seq_fibonacci(count)
  let mut result = []
  let mut a = 1.0
  let mut b = 1.0
  let mut i = 0.0
  while i < count
    push(result, a)
    let tmp = a + b
    a = b
    b = tmp
    i = i + 1.0
  end
  return result
end

// seq_sine(freq, phase, count) -> [sin(freq*0+phase), sin(freq*1+phase), ...]
fn seq_sine(freq, phase, count)
  let mut result = []
  let mut i = 0.0
  while i < count
    push(result, sin(freq * i + phase))
    i = i + 1.0
  end
  return result
end

// seq_random(count, seed_val) -> pseudo-random sequence of count floats in [0,1)
// Uses OctoFlow random(). seed_val is consumed to advance RNG state.
fn seq_random(count, seed_val)
  let mut result = []
  // Burn seed_val draws to offset the RNG state
  let mut s = 0.0
  while s < seed_val
    let _discard = random()
    s = s + 1.0
  end
  let mut i = 0.0
  while i < count
    push(result, random())
    i = i + 1.0
  end
  return result
end

// ── Sliding Window ──────────────────────────────────────────────

// seq_window(data, pos, win_size) -> extract window of win_size elements
// starting at pos. Pads with 0.0 if window extends past end of data.
fn seq_window(data, pos, win_size)
  let mut result = []
  let data_len = len(data)
  let mut i = 0.0
  while i < win_size
    let idx = pos + i
    if idx < data_len
      push(result, data[idx])
    else
      push(result, 0.0)
    end
    i = i + 1.0
  end
  return result
end

// ── Markov Transition Tables ────────────────────────────────────

// markov1_build(proto_seq, seq_len, proto_count) -> flat [proto_count x proto_count]
// table[from * proto_count + to] = count of transitions from -> to
fn markov1_build(proto_seq, seq_len, proto_count)
  let table_size = proto_count * proto_count
  let mut table = []
  let mut k = 0.0
  while k < table_size
    push(table, 0.0)
    k = k + 1.0
  end
  let mut i = 1.0
  while i < seq_len
    let from_p = proto_seq[i - 1.0]
    let to_p = proto_seq[i]
    let idx = from_p * proto_count + to_p
    table[idx] = table[idx] + 1.0
    i = i + 1.0
  end
  return table
end

// markov2_build(proto_seq, seq_len, proto_count) -> flat [proto_count^3]
// table[prev * pc^2 + curr * pc + next] = count
fn markov2_build(proto_seq, seq_len, proto_count)
  let pc2 = proto_count * proto_count
  let table_size = pc2 * proto_count
  let mut table = []
  let mut k = 0.0
  while k < table_size
    push(table, 0.0)
    k = k + 1.0
  end
  let mut i = 2.0
  while i < seq_len
    let prev_p = proto_seq[i - 2.0]
    let curr_p = proto_seq[i - 1.0]
    let next_p = proto_seq[i]
    let idx = prev_p * pc2 + curr_p * proto_count + next_p
    table[idx] = table[idx] + 1.0
    i = i + 1.0
  end
  return table
end

// ── Prediction ──────────────────────────────────────────────────

// markov1_predict(table, current_proto, proto_count) -> argmax next proto
// Returns the proto ID with the highest transition count from current_proto.
fn markov1_predict(table, current_proto, proto_count)
  let mut best_next = 0.0
  let mut best_count = -1.0
  let mut c = 0.0
  while c < proto_count
    let idx = current_proto * proto_count + c
    if table[idx] > best_count
      best_count = table[idx]
      best_next = c
    end
    c = c + 1.0
  end
  return best_next
end

// markov1_sample(table, from_proto, proto_count, temp)
// Temperature-based probabilistic sampling from Markov row.
// Complement to markov1_predict (greedy argmax).
fn markov1_sample(table, from_proto, proto_count, temp)
  let base = from_proto * proto_count
  let mut max_val = 0.0
  let mut ci = 0.0
  while ci < proto_count
    if table[base + ci] > max_val
      max_val = table[base + ci]
    end
    ci = ci + 1.0
  end
  if max_val < 0.5
    return floor(random() * proto_count)
  end
  let mut exp_sum = 0.0
  let mut probs = []
  ci = 0.0
  while ci < proto_count
    let e = exp((table[base + ci] - max_val) / temp)
    push(probs, e)
    exp_sum = exp_sum + e
    ci = ci + 1.0
  end
  let r = random() * exp_sum
  let mut cumsum = 0.0
  ci = 0.0
  while ci < proto_count
    cumsum = cumsum + probs[ci]
    if cumsum >= r
      return ci
    end
    ci = ci + 1.0
  end
  return proto_count - 1.0
end

// markov2_predict(table, prev_proto, curr_proto, proto_count) -> argmax next proto
// Returns the proto ID with the highest transition count from (prev, curr) context.
fn markov2_predict(table, prev_proto, curr_proto, proto_count)
  let pc2 = proto_count * proto_count
  let mut best_next = 0.0
  let mut best_count = -1.0
  let mut c = 0.0
  while c < proto_count
    let idx = prev_proto * pc2 + curr_proto * proto_count + c
    if table[idx] > best_count
      best_count = table[idx]
      best_next = c
    end
    c = c + 1.0
  end
  return best_next
end

// predict_n_steps(table, order, context, proto_count, n_steps)
// Chain predictions N times.
// order: 1.0 or 2.0
// context: [current] for order=1, [prev, current] for order=2
// Returns array of N predicted proto IDs.
fn predict_n_steps(table, order, context, proto_count, n_steps)
  let mut predictions = []
  // Copy context into mutable tracking variables
  let mut prev = 0.0
  let mut curr = 0.0
  if order < 1.5
    // Order 1: context has 1 element
    curr = context[0]
  else
    // Order 2: context has 2 elements [prev, current]
    prev = context[0]
    curr = context[1]
  end

  let mut step = 0.0
  while step < n_steps
    let mut next_pred = 0.0
    if order < 1.5
      next_pred = markov1_predict(table, curr, proto_count)
    else
      next_pred = markov2_predict(table, prev, curr, proto_count)
    end
    push(predictions, next_pred)
    // Shift context forward
    prev = curr
    curr = next_pred
    step = step + 1.0
  end
  return predictions
end

// ── Surprise / Anomaly Scoring ──────────────────────────────────

// compute_surprise(table, order, context, actual_proto, proto_count)
// Surprise = 1.0 - P(actual | context)
// P = count(context -> actual) / sum(count(context -> *))
// Returns float in [0, 1]. If no transitions from context, returns 1.0.
fn compute_surprise(table, order, context, actual_proto, proto_count)
  let mut actual_count = 0.0
  let mut total_count = 0.0

  if order < 1.5
    // First-order: context = [current]
    let from_p = context[0]
    let mut c = 0.0
    while c < proto_count
      let idx = from_p * proto_count + c
      let cnt = table[idx]
      total_count = total_count + cnt
      if c == actual_proto
        actual_count = cnt
      end
      c = c + 1.0
    end
  else
    // Second-order: context = [prev, curr]
    let prev_p = context[0]
    let curr_p = context[1]
    let pc2 = proto_count * proto_count
    let mut c = 0.0
    while c < proto_count
      let idx = prev_p * pc2 + curr_p * proto_count + c
      let cnt = table[idx]
      total_count = total_count + cnt
      if c == actual_proto
        actual_count = cnt
      end
      c = c + 1.0
    end
  end

  if total_count < 0.5
    return 1.0
  end
  let prob = actual_count / total_count
  return 1.0 - prob
end

// ── Log-Likelihood ──────────────────────────────────────────────

// sequence_log_likelihood(table, order, proto_seq, seq_len, proto_count)
// Sum of log(P(next | context)) over the sequence.
// Uses log(max(p, 0.0000000001)) to avoid log(0).
// Returns negative float (higher/less negative = more likely).
fn sequence_log_likelihood(table, order, proto_seq, seq_len, proto_count)
  let mut ll = 0.0
  let epsilon = 0.0000000001

  // Start index depends on order
  let mut start = 1.0
  if order > 1.5
    start = 2.0
  end

  let mut i = start
  while i < seq_len
    let actual_p = proto_seq[i]
    let mut actual_count = 0.0
    let mut total_count = 0.0

    if order < 1.5
      // First-order: context is proto_seq[i-1]
      let from_p = proto_seq[i - 1.0]
      let mut c = 0.0
      while c < proto_count
        let idx = from_p * proto_count + c
        let cnt = table[idx]
        total_count = total_count + cnt
        if c == actual_p
          actual_count = cnt
        end
        c = c + 1.0
      end
    else
      // Second-order: context is (proto_seq[i-2], proto_seq[i-1])
      let prev_p = proto_seq[i - 2.0]
      let curr_p = proto_seq[i - 1.0]
      let pc2 = proto_count * proto_count
      let mut c = 0.0
      while c < proto_count
        let idx = prev_p * pc2 + curr_p * proto_count + c
        let cnt = table[idx]
        total_count = total_count + cnt
        if c == actual_p
          actual_count = cnt
        end
        c = c + 1.0
      end
    end

    let mut prob = epsilon
    if total_count > 0.5
      let raw_prob = actual_count / total_count
      if raw_prob > epsilon
        prob = raw_prob
      end
    end
    ll = ll + log(prob)
    i = i + 1.0
  end
  return ll
end

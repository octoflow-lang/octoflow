// gpu_neural_net.flow — GPU Neural Network Inference
//
// "Forward pass as dispatch chain."
//
// Architecture: 256 → 64 (ReLU) → 16
// 16,384 weights layer 1 + 1,024 weights layer 2 = 17,408 parameters
// 2 dispatches. 0 CPU neuron iterations.
//
// Each workgroup computes one output neuron via shared-memory GEMV:
//   256 threads cooperatively reduce the dot product of a weight row x input vector.
//   Layer 1: 64 workgroups. Layer 2: 16 workgroups.
//
// Run: octoflow run examples/gpu_neural_net.flow --allow-ffi --allow-read

let N1 = 256.0
let M1 = 64.0
let M2 = 16.0

// ── Generate weights (deterministic pattern) ───────────────────────
let mut w1 = []
let mut i = 0.0
while i < M1 * N1
  let v = i - floor(i / 7.0) * 7.0
  push(w1, (v - 3.0) * 0.001)
  i = i + 1.0
end

let mut b1 = []
let mut i = 0.0
while i < M1
  push(b1, 0.0)
  i = i + 1.0
end

let mut w2 = []
let mut i = 0.0
while i < M2 * M1
  let v = i - floor(i / 5.0) * 5.0
  push(w2, (v - 2.0) * 0.01)
  i = i + 1.0
end

let mut b2 = []
let mut i = 0.0
while i < M2
  push(b2, 0.0)
  i = i + 1.0
end

// Input: [1, 2, 3, ..., 256]
let mut x = []
let mut i = 0.0
while i < N1
  push(x, i + 1.0)
  i = i + 1.0
end

// ── Boot VMs (4 bindings each: weights, input, bias, output) ────────
let vm1 = loom_boot(1.0, 4.0, M1 * N1)
let vm2 = loom_boot(1.0, 4.0, M2 * M1)
loom_prefetch("tests/gpu_shaders/22_gemv_relu.spv")
loom_prefetch("tests/gpu_shaders/23_gemv.spv")

// Layer 1 registers: 0=W1, 1=x, 2=b1, 3=h
vm_write_register(vm1, 0.0, 0.0, w1)
vm_write_register(vm1, 0.0, 1.0, x)
vm_write_register(vm1, 0.0, 2.0, b1)
let mut hz = []
let mut i = 0.0
while i < M1
  push(hz, 0.0)
  i = i + 1.0
end
vm_write_register(vm1, 0.0, 3.0, hz)

// ── Forward pass ────────────────────────────────────────────────────
let t0 = time()

// Layer 1: h = relu(W1 * x + b1)
loom_dispatch(vm1, "tests/gpu_shaders/22_gemv_relu.spv", [N1], M1)
let p1 = loom_build(vm1)
loom_run(p1)
loom_free(p1)

// Read hidden layer output
let h = loom_read(vm1, 0.0, 3.0, M1)

// Layer 2 registers: 0=W2, 1=h, 2=b2, 3=y
vm_write_register(vm2, 0.0, 0.0, w2)
vm_write_register(vm2, 0.0, 1.0, h)
vm_write_register(vm2, 0.0, 2.0, b2)
let mut yz = []
let mut i = 0.0
while i < M2
  push(yz, 0.0)
  i = i + 1.0
end
vm_write_register(vm2, 0.0, 3.0, yz)

// Layer 2: y = W2 * h + b2
loom_dispatch(vm2, "tests/gpu_shaders/23_gemv.spv", [M1], M2)
let p2 = loom_build(vm2)
loom_run(p2)
loom_free(p2)

let t1 = time()
let total_ms = (t1 - t0) * 1000.0

// ── Download output ────────────────────────────────────────────────
let mut gpu_y = []
let gy_raw = loom_read(vm2, 0.0, 3.0, M2)
let mut i = 0.0
while i < M2
  push(gpu_y, gy_raw[int(i)])
  i = i + 1.0
end

// ── CPU verification (same computation) ────────────────────────────
let mut h_cpu = []
let mut j = 0.0
while j < M1
  let mut dot = 0.0
  let mut i = 0.0
  while i < N1
    dot = dot + w1[int(j * N1 + i)] * x[int(i)]
    i = i + 1.0
  end
  dot = dot + b1[int(j)]
  if dot < 0.0
    dot = 0.0
  end
  push(h_cpu, dot)
  j = j + 1.0
end

let mut y_cpu = []
let mut j = 0.0
while j < M2
  let mut dot = 0.0
  let mut i = 0.0
  while i < M1
    dot = dot + w2[int(j * M1 + i)] * h_cpu[int(i)]
    i = i + 1.0
  end
  dot = dot + b2[int(j)]
  push(y_cpu, dot)
  j = j + 1.0
end

// ── Compare GPU vs CPU ─────────────────────────────────────────────
let mut max_err = 0.0
let mut i = 0.0
while i < M2
  let err = abs(gpu_y[int(i)] - y_cpu[int(i)])
  if err > max_err
    max_err = err
  end
  i = i + 1.0
end

let mut best_idx = 0.0
let mut best_val = gpu_y[0]
let mut i = 1.0
while i < M2
  if gpu_y[int(i)] > best_val
    best_val = gpu_y[int(i)]
    best_idx = i
  end
  i = i + 1.0
end

// ── Report ─────────────────────────────────────────────────────────
print("")
print("OctoFlow GPU Neural Network Inference")
print("  Architecture: {N1} -> {M1} (ReLU) -> {M2}")
print("  Parameters: 17408 (16384 + 1024 weights)")
print("  Dispatches: 2 (hidden layer + output layer)")
print("  CPU neuron iterations: 0")
print("  Total time: {total_ms} ms")
print("")

print("  Output logits (GPU):")
let mut i = 0.0
while i < M2
  let gy = gpu_y[int(i)]
  let cy = y_cpu[int(i)]
  print("    [{i}] gpu={gy}  cpu={cy}")
  i = i + 1.0
end

print("")
print("  Predicted class: {best_idx} (logit={best_val})")
print("  Max GPU-CPU error: {max_err}")

if max_err < 0.01
  print("  MATCH (GPU matches CPU within 0.01)")
else
  print("  MISMATCH (error too large)")
end

print("")
loom_shutdown(vm1)
loom_shutdown(vm2)

// gpu_database.flow — GPU Database Engine: Query Plan as Dispatch Chain
//
// "If GPU is the computer, query plan becomes dispatch chain."
//
// 65,536 employee records processed on GPU.
// Multi-pass parallel reduction (256 workgroups → 1 value).
//
// SQL equivalent:
//   SELECT SUM(salary), COUNT(*) FROM employees WHERE salary > 32768
//
// GPU dispatch chain:
//   [filter: gt_scalar] → [mask: mul_ab] →
//   [reduce SUM pass 1+2] → [reduce COUNT pass 1+2]
//
// Run: octoflow run examples/gpu_database.flow --allow-ffi --allow-read

let N = 65536.0
let WG_SIZE = 256.0
let NUM_WG = N / WG_SIZE
let THRESHOLD = 32768.0

// ── Boot VMs for each shader type ────────────────────────────────────
let vm_gt = loom_boot(1.0, 2.0, N)
let vm_mul = loom_boot(1.0, 3.0, N)
let vm_r1s = loom_boot(1.0, 2.0, N)
let vm_r2s = loom_boot(1.0, 2.0, NUM_WG)
let vm_r1c = loom_boot(1.0, 2.0, N)
let vm_r2c = loom_boot(1.0, 2.0, NUM_WG)

loom_prefetch("tests/gpu_shaders/15_gt_scalar.spv")
loom_prefetch("tests/gpu_shaders/18_mul_ab.spv")
loom_prefetch("stdlib/loom/kernels/reduce/reduce_sum.spv")

// Upload salary data: [1, 2, 3, ..., 65536]
let mut salaries = []
let mut i = 0.0
while i < N
  push(salaries, i + 1.0)
  i = i + 1.0
end
vm_write_register(vm_gt, 0.0, 0.0, salaries)

// Zero arrays
let mut zeros = []
let mut i = 0.0
while i < N
  push(zeros, 0.0)
  i = i + 1.0
end

let mut pz = []
let mut i = 0.0
while i < NUM_WG
  push(pz, 0.0)
  i = i + 1.0
end

// ── Stage 1: FILTER — salary > 32768 → boolean mask ─────────────────
let t0 = time()

vm_write_register(vm_gt, 0.0, 1.0, zeros)
loom_dispatch(vm_gt, "tests/gpu_shaders/15_gt_scalar.spv", [THRESHOLD], NUM_WG)
let pg = loom_build(vm_gt)
loom_run(pg)
loom_free(pg)
let mask = loom_read(vm_gt, 0.0, 1.0, N)

// ── Stage 2: MASK — salary * mask → masked_salary ────────────────────
vm_write_register(vm_mul, 0.0, 0.0, salaries)
vm_write_register(vm_mul, 0.0, 1.0, mask)
vm_write_register(vm_mul, 0.0, 2.0, zeros)
loom_dispatch(vm_mul, "tests/gpu_shaders/18_mul_ab.spv", [], NUM_WG)
let pm = loom_build(vm_mul)
loom_run(pm)
loom_free(pm)
let masked = loom_read(vm_mul, 0.0, 2.0, N)

// ── Stage 3: REDUCE SUM pass 1 — masked → 256 partials ──────────────
vm_write_register(vm_r1s, 0.0, 0.0, masked)
vm_write_register(vm_r1s, 0.0, 1.0, pz)
loom_dispatch(vm_r1s, "stdlib/loom/kernels/reduce/reduce_sum.spv", [], NUM_WG)
let ps1 = loom_build(vm_r1s)
loom_run(ps1)
loom_free(ps1)
let partial_sum = loom_read(vm_r1s, 0.0, 1.0, NUM_WG)

// ── Stage 4: REDUCE SUM pass 2 — 256 partials → 1 ───────────────────
vm_write_register(vm_r2s, 0.0, 0.0, partial_sum)
let mut rz = [0.0]
vm_write_register(vm_r2s, 0.0, 1.0, rz)
loom_dispatch(vm_r2s, "stdlib/loom/kernels/reduce/reduce_sum.spv", [], 1.0)
let ps2 = loom_build(vm_r2s)
loom_run(ps2)
loom_free(ps2)
let sum_result = loom_read(vm_r2s, 0.0, 1.0, 1.0)
let gpu_sum = sum_result[0]

// ── Stage 5: REDUCE COUNT pass 1 — mask → 256 partials ──────────────
vm_write_register(vm_r1c, 0.0, 0.0, mask)
vm_write_register(vm_r1c, 0.0, 1.0, pz)
loom_dispatch(vm_r1c, "stdlib/loom/kernels/reduce/reduce_sum.spv", [], NUM_WG)
let pc1 = loom_build(vm_r1c)
loom_run(pc1)
loom_free(pc1)
let partial_count = loom_read(vm_r1c, 0.0, 1.0, NUM_WG)

// ── Stage 6: REDUCE COUNT pass 2 — 256 partials → 1 ─────────────────
vm_write_register(vm_r2c, 0.0, 0.0, partial_count)
let mut rz2 = [0.0]
vm_write_register(vm_r2c, 0.0, 1.0, rz2)
loom_dispatch(vm_r2c, "stdlib/loom/kernels/reduce/reduce_sum.spv", [], 1.0)
let pc2 = loom_build(vm_r2c)
loom_run(pc2)
loom_free(pc2)
let count_result = loom_read(vm_r2c, 0.0, 1.0, 1.0)
let gpu_count = count_result[0]

let t1 = time()
let total_ms = (t1 - t0) * 1000.0

let gpu_avg = gpu_sum / gpu_count

// CPU verification
let expected_count = 32768.0
let expected_sum = 1610678272.0
let expected_avg = expected_sum / expected_count

print("")
print("OctoFlow GPU Database Engine")
print("  Records: {N}")
print("  Query: SELECT SUM(salary), COUNT(*) WHERE salary > {THRESHOLD}")
print("  Dispatches: 6 (filter + mask + 2x reduce_sum + 2x reduce_count)")
print("  CPU row iterations: 0")
print("  Total time: {total_ms} ms")
print("  SUM:     {gpu_sum}  (expected {expected_sum})")
print("  COUNT:   {gpu_count}  (expected {expected_count})")
print("  AVG:     {gpu_avg}  (expected {expected_avg})")

let sum_err = abs(gpu_sum - expected_sum)
let count_err = abs(gpu_count - expected_count)
let sum_rel = sum_err / expected_sum

if count_err < 1.0
  if sum_rel < 0.001
    print("  MATCH (count exact, sum within 0.1%)")
  else
    print("  MISMATCH: SUM relative error: {sum_rel}")
  end
else
  print("  MISMATCH: COUNT error: {count_err}")
end

print("")
loom_shutdown(vm_gt)
loom_shutdown(vm_mul)
loom_shutdown(vm_r1s)
loom_shutdown(vm_r2s)
loom_shutdown(vm_r1c)
loom_shutdown(vm_r2c)

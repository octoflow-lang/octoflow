{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# octo-llm GRPO Fine-Tune\n\n**Qwen3-1.7B** → QLoRA + GRPO (compiler-as-reward-model) → Merge → Q5_K_M GGUF\n\nThe LLM doesn't need to know how to code — it needs to understand what the user wants.\nOctoFlow's compiler handles correctness. GRPO trains the model to generate code the compiler accepts.\n\n**How it works:**\n1. Sample N completions per prompt from Qwen3-1.7B\n2. Score each with OctoFlow syntax checker (reward function)\n3. Group-rank: better completions get higher advantage\n4. Policy gradient update — model learns what makes correct OctoFlow\n\n**No labeled data needed — the compiler IS the teacher.**\n\nAttach dataset `octoflow-training-data`, enable **GPU T4**, Internet ON, then Run All."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": "# ── Install + GPU Check ──\n!pip install -q \"transformers>=4.45\" \"peft>=0.13\" \"trl>=0.15\" \"bitsandbytes>=0.44\" datasets accelerate sentencepiece\n\nimport torch, os, glob, json, random, re, gc\n\nassert torch.cuda.is_available(), \"Enable GPU in Kaggle settings!\"\ngpu_name = torch.cuda.get_device_name(0)\ngpu_free = torch.cuda.mem_get_info()[0] / 1024**3\nprint(f\"GPU: {gpu_name} ({gpu_free:.1f} GB free)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Configuration ──\nMODEL_NAME = \"Qwen/Qwen3-1.7B\"\n\n# Paths\nOUTPUT_DIR   = \"/kaggle/working/octo-llm-grpo\"\nADAPTER_DIR  = \"/kaggle/working/octo-llm-grpo-adapter\"\nMERGED_DIR   = \"/kaggle/working/octo-llm-merged\"\nGGUF_DIR     = \"/kaggle/working/octo-llm-gguf\"\n\n# QLoRA\nLORA_R       = 16\nLORA_ALPHA   = 32\nLORA_DROPOUT = 0.05\nTARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n\n# GRPO\nNUM_PROMPTS       = 3000   # prompts to train on (subsampled from 52K bank)\nNUM_GENERATIONS   = 4      # completions per prompt\nMAX_COMPLETION_LEN = 384   # max tokens per completion\nTEMPERATURE       = 0.8    # sampling temperature for diversity\nGRPO_LR           = 5e-6   # learning rate (conservative for RL)\nGRPO_EPOCHS       = 2\nGRPO_BATCH        = 2      # prompts per device per step\nGRPO_GRAD_ACCUM   = 4      # effective batch = 8 prompts = 32 completions\n\n# Reward weights (max total = 5.0)\nW_STRUCTURE   = 1.0   # has OctoFlow keywords/structure\nW_BLOCKS      = 1.0   # blocks properly matched (fn..end, for..end)\nW_NO_FOREIGN  = 1.0   # no Python/JS/C++ syntax\nW_IDIOMS      = 1.0   # correct OctoFlow idioms\nW_CONCISE     = 0.5   # conciseness bonus\nW_NO_MISTAKES = 0.5   # avoids known LLM mistakes\nMAX_REWARD    = 5.0\n\nsteps_per_epoch = NUM_PROMPTS // (GRPO_BATCH * GRPO_GRAD_ACCUM)\nprint(f\"Config: {MODEL_NAME}\")\nprint(f\"GRPO: {NUM_PROMPTS} prompts × {NUM_GENERATIONS} gens = {NUM_PROMPTS * NUM_GENERATIONS} completions/epoch\")\nprint(f\"Steps/epoch: {steps_per_epoch}, Total: {steps_per_epoch * GRPO_EPOCHS}\")\nprint(f\"Est time on T4: ~{steps_per_epoch * GRPO_EPOCHS * 45 / 3600:.1f}h (at ~45s/step)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── L0 Core Knowledge + System Prompt ──\n# This is the core OctoFlow syntax reference, always included in the prompt.\n# The context engine provides more detail at inference time, but L0 is the foundation.\n\nL0_CORE = \"\"\"\\\n# OctoFlow Core\n\n## Syntax\nlet x = 42.0              // immutable\nlet mut y = 0.0            // mutable\nfn add(a, b)\n    return a + b\nend\nif x > 0\n    print(\"positive\")\nelif x == 0\n    print(\"zero\")\nelse\n    print(\"negative\")\nend\nfor i in range(0, 10)\n    print(\"{i}\")\nend\nwhile y < 100\n    y = y + 1\nend\nuse \"math\"                 // import module\n\n## Types\nfloat (f32): 42.0 | int (i64): 42 | string: \"hello {name}\" | array: [] | map: map() | none\nBooleans: 1.0=true, 0.0=false. int+float→float. Operators: + - * / % == != < > <= >= && || !\n\n## Core Builtins\nprint(\"text {var}\") len(x) type_of(x) int(x) float(x) str(x) is_none(x)\nabs(x) sqrt(x) pow(x,n) round(x) floor(x) ceil(x) random()\npush(arr, val) pop(arr) slice(arr, s, e) sort_array(arr)\nfilter(arr, fn(x) cond end) map_each(arr, fn(x) expr end)\nlet mut m = map() | m[\"key\"] = val | map_get(m, \"key\") | map_keys(m)\nlet r = try(expr)  // r.ok r.value r.error\n\n## Rules\n- All blocks end with `end`. No braces. No semicolons.\n- print() ONLY takes strings: print(\"{x}\") never print(x)\n- Functions not methods: push(arr, x) not arr.push(x)\n- Modules: use \"data/csv\" use \"stats/descriptive\" use \"web/http\"\n\"\"\"\n\nSYSTEM_PROMPT = (\n    \"You are octo-llm, an AI assistant for OctoFlow. \"\n    \"Users describe what they want, and you generate correct OctoFlow code. \"\n    \"Respond ONLY with OctoFlow code — no explanations, no markdown fences.\\n\\n\"\n    + L0_CORE\n)\n\nprint(f\"System prompt: {len(SYSTEM_PROMPT)} chars (~{len(SYSTEM_PROMPT)//4} tokens)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Load Prompt Bank + Chain Discovery Prompts ──\nimport zipfile\n\n# Discover training data (handles various Kaggle mount points)\ndef find_data_file(name):\n    for base in [\"/kaggle/input\", \"/kaggle/working/training-data\"]:\n        for match in glob.glob(f\"{base}/**/{name}\", recursive=True):\n            return match\n    return None\n\n# Try to find data; if not found, try extracting from zip\nbatch1 = find_data_file(\"batch_001.jsonl\")\nif not batch1:\n    zip_matches = glob.glob(\"/kaggle/input/**/*.zip\", recursive=True)\n    for zf in zip_matches:\n        extract_to = \"/kaggle/working/training-data\"\n        if not os.path.exists(extract_to):\n            print(f\"Extracting {zf}...\")\n            os.makedirs(extract_to, exist_ok=True)\n            with zipfile.ZipFile(zf, \"r\") as z:\n                z.extractall(extract_to)\n    batch1 = find_data_file(\"batch_001.jsonl\")\n\nassert batch1, \"Training data not found! Attach octoflow-training-data dataset.\"\n\ndef extract_prompts(files):\n    \"\"\"Extract unique prompts from JSONL files.\"\"\"\n    prompts = []\n    seen = set()\n    for fpath in files:\n        if not fpath or not os.path.exists(fpath):\n            continue\n        with open(fpath, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                if not line:\n                    continue\n                obj = json.loads(line)\n                p = obj.get(\"prompt\", \"\")\n                if p and len(p) > 10 and p not in seen:\n                    # Skip error-fix prompts that are too long (> 500 chars)\n                    if len(p) < 500:\n                        prompts.append(p)\n                        seen.add(p)\n    return prompts\n\ndata_files = [find_data_file(n) for n in [\n    \"batch_001.jsonl\", \"batch_002_medium.jsonl\",\n    \"batch_003_hard.jsonl\", \"batch_004_post3b.jsonl\",\n    \"dpo_001.jsonl\",\n]]\nall_prompts = extract_prompts(data_files)\nprint(f\"Loaded {len(all_prompts)} unique prompts from training data\")\n\n# ── Chain Discovery Prompts ──\n# Compositional tasks that require chaining multiple OctoFlow modules.\n# The model learns to compose primitives: csv+stats, image+transform, http+json, etc.\nCHAIN_PROMPTS = [\n    # Data pipelines\n    \"Read a CSV file, filter rows where price > 100, compute the average, and print it\",\n    \"Load CSV data, sort by date column, compute running total of amounts, print final total\",\n    \"Read a JSON config file, extract the database host and port, print connection string\",\n    \"Parse a CSV with headers, group rows by category, count each group, print summary table\",\n    \"Read two CSV files, merge them by matching id column, export combined result\",\n    \"Load a dataset, remove rows with missing values, compute mean of each column, print report\",\n    \"Read a log file line by line, parse timestamps, count entries per hour, print histogram\",\n    \"Import CSV data, compute min max mean stddev for price column, print statistics summary\",\n    \"Read a JSON array file, filter objects where status equals active, count and print result\",\n    \"Load CSV sales data, compute total revenue per product, sort descending, print top 5\",\n    \"Read a text file, split into words, count unique words, print the 10 most frequent\",\n    \"Parse CSV stock data, compute daily returns from close prices, print mean return\",\n    # Web + data\n    \"Create an HTTP server that reads config from a JSON file and responds with formatted data\",\n    \"Build a REST API with GET /items that reads from a CSV and returns JSON\",\n    \"Create an HTTP health check endpoint that returns server uptime as JSON\",\n    \"Build a webhook receiver that logs incoming POST data to a CSV file\",\n    \"Create an HTTP server with two endpoints: GET /status and POST /data that saves to file\",\n    # ML/Stats chains\n    \"Load stock prices from CSV, compute 20-day SMA and 20-day EMA, print both values\",\n    \"Read a dataset, split 80/20 into train and test sets, train KNN with k=5, print accuracy\",\n    \"Generate 1000 random numbers, compute mean median and standard deviation, print results\",\n    \"Load two price arrays, compute their Pearson correlation coefficient, print it\",\n    \"Read sensor data from CSV, compute z-scores, flag readings where abs z-score > 3\",\n    \"Compute RSI for stock closing prices with period 14, print the latest RSI value\",\n    \"Load a dataset with x and y columns, run linear regression, print slope and intercept\",\n    \"Generate random data points, run k-means clustering with k=3, print cluster centers\",\n    \"Read exam scores from CSV, compute percentile ranks for each student, print results\",\n    \"Load temperature data, compute 7-day moving average, print smoothed values\",\n    # Image/media chains\n    \"Load a BMP image, convert each pixel to grayscale by averaging RGB channels, save result\",\n    \"Create a 256x256 gradient image from black to white, save as BMP file\",\n    \"Read a BMP image, flip it horizontally by reversing each row, save the mirrored image\",\n    \"Generate a sine wave audio signal at 440 Hz for 2 seconds, save as WAV file\",\n    \"Load a BMP image, increase brightness by adding 30 to each channel, clamp to 255, save\",\n    # GPU chains\n    \"Generate two random vectors with 10000 elements on GPU, compute their dot product, print it\",\n    \"Create two 100x100 matrices on GPU, multiply them, print the sum of the result\",\n    \"Generate 1 million random numbers on GPU, compute their mean and max, print both\",\n    \"Compute softmax of a 1000-element vector on GPU, verify values sum to approximately 1.0\",\n    \"Upload an array to GPU, scale every element by 3.5, download result, print first 10 values\",\n    # Crypto + encoding\n    \"Read a file as string, compute its SHA-256 hash, print the hex digest\",\n    \"Generate a random UUID, base64-encode it, print both original and encoded form\",\n    \"Read a password string, hash it with SHA-256, compare with a stored hash, print match result\",\n    \"Encode a string as base64, decode it back, verify round-trip produces original string\",\n    # Multi-domain compositions\n    \"Create a function to validate email addresses using string operations, test with 5 examples\",\n    \"Implement binary search on a sorted array of 1000 integers, print whether target was found\",\n    \"Build a priority queue using an array with push and pop-min operations, test with 10 items\",\n    \"Read environment variables for HOST and PORT, validate they exist, print server address\",\n    \"Create a timer that measures execution time of sorting 10000 numbers, print elapsed seconds\",\n    \"Build a simple key-value store with set get and delete functions, demonstrate usage\",\n    \"Generate multiplication table for 1 through 12, format as aligned columns, print it\",\n    \"Implement Caesar cipher with encrypt and decrypt functions, test with a sample message\",\n    \"Read a CSV file, pivot data by category column, compute sum per category, export as JSON\",\n    \"Generate Fibonacci sequence up to 50 terms, filter for even numbers, print them\",\n    \"Load a text file, count sentences by splitting on periods, compute average sentence length\",\n    \"Create a function to check if a string is a palindrome, test with 5 example strings\",\n    \"Read command-line args, parse named flags, print each flag name and value\",\n    \"Build a simple calculator that evaluates addition subtraction multiplication division from input\",\n    \"Generate 100 random integers, sort them, use binary search to find specific values\",\n]\n\nall_prompts.extend(CHAIN_PROMPTS)\nprint(f\"Added {len(CHAIN_PROMPTS)} chain discovery prompts → {len(all_prompts)} total\")\n\n# Subsample for GRPO training\nrandom.seed(42)\nrandom.shuffle(all_prompts)\ntrain_prompts = all_prompts[:NUM_PROMPTS]\nprint(f\"Using {len(train_prompts)} prompts for GRPO training\")\n\n# Build dataset with chat format\nfrom datasets import Dataset\ndataset_rows = [{\"prompt\": [\n    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n    {\"role\": \"user\", \"content\": p},\n]} for p in train_prompts]\n\ntrain_dataset = Dataset.from_list(dataset_rows)\nprint(f\"Dataset ready: {len(train_dataset)} rows\")\nprint(f\"Sample: {train_dataset[0]['prompt'][1]['content'][:80]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── OctoFlow Reward Function ──\n# The compiler-as-reward-model: scores generated OctoFlow code quality.\n# No human labeling needed — syntax rules are the teacher.\n\ndef extract_flow_code(text):\n    \"\"\"Extract OctoFlow code from LLM response.\"\"\"\n    if not text or not text.strip():\n        return \"\"\n    # Try ```flow ... ``` or ```octoflow ... ```\n    m = re.search(r'```(?:flow|octoflow)\\s*\\n(.*?)```', text, re.DOTALL)\n    if m:\n        return m.group(1).strip()\n    # Try generic ``` ... ```\n    m = re.search(r'```\\s*\\n(.*?)```', text, re.DOTALL)\n    if m:\n        return m.group(1).strip()\n    # Raw code — if it looks like OctoFlow, use as-is\n    if any(kw in text for kw in ['let ', 'fn ', 'print(', 'for ', 'use \"']):\n        return text.strip()\n    return \"\"\n\ndef score_octoflow(code):\n    \"\"\"Score OctoFlow code quality. Returns 0.0 to MAX_REWARD.\"\"\"\n    if not code or not code.strip():\n        return 0.0\n\n    lines = [l for l in code.split('\\n') if l.strip()]\n    if not lines:\n        return 0.0\n\n    score = 0.0\n\n    # ── 1. Structure (+1.0): Has OctoFlow keywords ──\n    octo_keywords = ('let ', 'let mut ', 'fn ', 'print(', 'println(',\n                     'for ', 'if ', 'while ', 'use \"', 'match ', 'struct ')\n    has_kw = any(l.strip().startswith(octo_keywords) for l in lines)\n    if has_kw:\n        score += W_STRUCTURE\n    elif len(lines) >= 2:\n        score += W_STRUCTURE * 0.3  # has content, just no obvious keywords\n\n    # ── 2. Block matching (+1.0): fn/for/if/while..end ──\n    openers = 0\n    closers = 0\n    for l in lines:\n        s = l.strip()\n        if any(s.startswith(kw) for kw in ('fn ', 'for ', 'while ', 'match ')):\n            openers += 1\n        elif s.startswith('if ') and not s.startswith('if r.'):\n            openers += 1\n        if s == 'end':\n            closers += 1\n    if openers == closers:\n        score += W_BLOCKS\n    elif openers > 0 and abs(openers - closers) <= 1:\n        score += W_BLOCKS * 0.5\n\n    # ── 3. No foreign syntax (+1.0) ──\n    penalty = 0.0\n    for pattern, w in [\n        ('def ', 0.4), ('class ', 0.4), ('import ', 0.3),\n        ('from ', 0.2), ('self.', 0.3), ('console.log', 0.4),\n        ('System.out', 0.4), ('const ', 0.3), ('var ', 0.3),\n        ('#include', 0.4), ('std::', 0.4), ('public ', 0.3),\n    ]:\n        if pattern in code:\n            penalty += w\n    # Curly-brace blocks (not string interpolation \"{var}\")\n    for l in lines:\n        s = l.strip()\n        if s in ('{', '}') or s.endswith('{') or s.startswith('}'):\n            penalty += 0.3\n            break\n    # Semicolons at end of statements\n    for l in lines:\n        s = l.strip()\n        if s.endswith(';') and not s.startswith('//'):\n            penalty += 0.1\n    score += max(0.0, W_NO_FOREIGN - penalty)\n\n    # ── 4. OctoFlow idioms (+1.0) ──\n    idiom = 0.0\n    if re.search(r'print\\s*\\(\\s*\".*\\{.*\\}.*\"\\s*\\)', code):\n        idiom += 0.3   # string interpolation in print\n    elif 'print(' in code:\n        idiom += 0.1   # at least uses print\n    if 'let ' in code:\n        idiom += 0.2\n    if any(l.strip().startswith('use \"') for l in lines):\n        idiom += 0.2   # module import\n    if any(l.strip().startswith('fn ') for l in lines):\n        idiom += 0.15  # function definition\n    if any(kw in code for kw in ['push(', 'pop(', 'len(', 'sort_array(', 'map_each(']):\n        idiom += 0.15  # function-style calls (not methods)\n    score += min(idiom, W_IDIOMS)\n\n    # ── 5. Conciseness (+0.5) ──\n    n = len(lines)\n    if 1 <= n <= 25:\n        score += W_CONCISE\n    elif n <= 50:\n        score += W_CONCISE * 0.5\n\n    # ── 6. Known mistakes penalty (-0.5 max) ──\n    mistakes = 0.0\n    if re.search(r'print\\s*\\(\\s*[a-zA-Z_]\\w*\\s*\\)', code):\n        mistakes += 0.15   # print(var) instead of print(\"{var}\")\n    if re.search(r'\\.\\s*push\\s*\\(', code):\n        mistakes += 0.15   # arr.push() instead of push(arr, x)\n    if re.search(r'\\.\\s*length\\b', code):\n        mistakes += 0.1    # arr.length instead of len(arr)\n    if re.search(r'\\belif\\s*:', code):\n        mistakes += 0.1    # elif: with colon\n    if re.search(r'\\bTrue\\b', code):\n        mistakes += 0.1    # True instead of 1.0\n    if re.search(r'\\bFalse\\b', code):\n        mistakes += 0.1    # False instead of 0.0\n    score -= min(mistakes, W_NO_MISTAKES)\n\n    return max(0.0, min(score, MAX_REWARD))\n\n\ndef octoflow_reward(completions, **kwargs):\n    \"\"\"GRPO reward function. Scores each completion.\"\"\"\n    rewards = []\n    for c in completions:\n        text = c if isinstance(c, str) else str(c)\n        code = extract_flow_code(text)\n        rewards.append(float(score_octoflow(code)))\n    return rewards\n\n\n# ── Sanity check the reward function ──\ntests = [\n    (\"Good OctoFlow\",\n     'let x = 42\\nlet y = x * 2\\nprint(\"{y}\")', 2.5),\n    (\"With function\",\n     'fn factorial(n)\\n    if n <= 1\\n        return 1\\n    end\\n    return n * factorial(n - 1)\\nend\\nlet r = factorial(5)\\nprint(\"{r}\")', 3.5),\n    (\"With module\",\n     'use \"data/csv\"\\nlet data = read_csv(\"input.csv\")\\nlet n = len(data)\\nprint(\"{n} rows loaded\")', 3.5),\n    (\"Python code\",\n     'def factorial(n):\\n    if n <= 1:\\n        return 1\\n    return n * factorial(n-1)\\nprint(factorial(5))', 0.5),\n    (\"JavaScript\",\n     'const x = 42;\\nconsole.log(x);', 0.0),\n    (\"Empty\", '', 0.0),\n]\n\nprint(\"Reward function sanity check:\")\nfor name, code, min_expected in tests:\n    s = score_octoflow(code)\n    ok = \"OK\" if s >= min_expected else \"LOW\"\n    print(f\"  [{ok}] {name}: {s:.1f} (expected >= {min_expected})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Load Model with QLoRA ──\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME, quantization_config=bnb_config,\n    device_map=\"auto\", trust_remote_code=True,\n)\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n\nlora_config = LoraConfig(\n    r=LORA_R, lora_alpha=LORA_ALPHA,\n    target_modules=TARGET_MODULES,\n    lora_dropout=LORA_DROPOUT,\n    bias=\"none\", task_type=\"CAUSAL_LM\",\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\nprint(f\"\\nModel loaded: {MODEL_NAME}\")\nprint(f\"GPU memory: {torch.cuda.memory_allocated()/1024**3:.1f} GB / \"\n      f\"{torch.cuda.mem_get_info()[1]/1024**3:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── GRPO Training ──\n# Group Relative Policy Optimization: no separate reward model or value function.\n# Advantages are computed within each group of completions for the same prompt.\n# Completion that scores highest in its group gets positive advantage → reinforced.\n\nfrom trl import GRPOTrainer, GRPOConfig\n\ngrpo_config = GRPOConfig(\n    output_dir=OUTPUT_DIR,\n\n    # GRPO generation\n    num_generations=NUM_GENERATIONS,\n    max_completion_length=MAX_COMPLETION_LEN,\n\n    # Training\n    num_train_epochs=GRPO_EPOCHS,\n    per_device_train_batch_size=GRPO_BATCH,\n    gradient_accumulation_steps=GRPO_GRAD_ACCUM,\n    learning_rate=GRPO_LR,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.10,\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n\n    # Memory optimization\n    bf16=True,\n    fp16=False,\n    gradient_checkpointing=True,\n    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n    optim=\"adamw_8bit\",\n\n    # Logging\n    logging_steps=5,\n    save_strategy=\"steps\",\n    save_steps=100,\n    save_total_limit=3,\n    report_to=\"none\",\n    seed=42,\n    remove_unused_columns=False,\n    dataloader_num_workers=2,\n)\n\ntrainer = GRPOTrainer(\n    model=model,\n    reward_funcs=[octoflow_reward],\n    args=grpo_config,\n    train_dataset=train_dataset,\n    processing_class=tokenizer,\n)\n\ntotal_steps = steps_per_epoch * GRPO_EPOCHS\nprint(f\"Starting GRPO training:\")\nprint(f\"  {GRPO_EPOCHS} epochs × {steps_per_epoch} steps = {total_steps} total steps\")\nprint(f\"  {NUM_GENERATIONS} completions/prompt, {MAX_COMPLETION_LEN} max tokens\")\nprint(f\"  Effective batch: {GRPO_BATCH * GRPO_GRAD_ACCUM} prompts = \"\n      f\"{GRPO_BATCH * GRPO_GRAD_ACCUM * NUM_GENERATIONS} completions/update\")\n\ntrainer.train()\n\n# Save adapter\nos.makedirs(ADAPTER_DIR, exist_ok=True)\ntrainer.save_model(ADAPTER_DIR)\ntokenizer.save_pretrained(ADAPTER_DIR)\nprint(f\"\\nGRPO adapter saved to {ADAPTER_DIR}\")\n\ndel trainer\ntorch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Post-Training Evaluation ──\nfrom peft import PeftModel\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME, quantization_config=bnb_config,\n    device_map=\"auto\", trust_remote_code=True,\n)\ngrpo_model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\ngrpo_model.eval()\n\neval_prompts = [\n    \"Print hello world\",\n    \"Read a CSV file and print the number of rows\",\n    \"Create a function that returns the factorial of a number\",\n    \"Sort an array of numbers in ascending order and print the result\",\n    \"Create a simple HTTP server that responds with JSON\",\n    \"Read lines from a file, filter lines containing error, and count them\",\n    \"Compute the SHA-256 hash of a string and print the hex digest\",\n    \"Generate random vectors on GPU, compute their dot product, print result\",\n    \"Load CSV data, filter rows where value > 50, print how many remain\",\n    \"Read stock prices, compute 20-day moving average, print the latest value\",\n]\n\ntotal_reward = 0.0\nresults = []\nprint(\"Post-GRPO Evaluation\")\nprint(\"=\" * 60)\n\nfor prompt in eval_prompts:\n    msgs = [\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    text = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer(text, return_tensors=\"pt\").to(grpo_model.device)\n\n    with torch.no_grad():\n        out = grpo_model.generate(\n            **inputs, max_new_tokens=256, temperature=0.0, do_sample=False,\n        )\n    gen = tokenizer.decode(out[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n\n    code = extract_flow_code(gen)\n    reward = score_octoflow(code)\n    total_reward += reward\n    results.append((prompt, reward, gen[:200]))\n\n    status = \"PASS\" if reward >= 3.0 else \"WEAK\" if reward >= 1.5 else \"FAIL\"\n    print(f\"\\n[{status} {reward:.1f}] >>> {prompt}\")\n    print(gen[:300])\n    print(\"─\" * 40)\n\navg_reward = total_reward / len(eval_prompts)\npassing = sum(1 for _, r, _ in results if r >= 3.0)\nprint(f\"\\n{'=' * 60}\")\nprint(f\"Average reward: {avg_reward:.2f} / {MAX_REWARD}\")\nprint(f\"Passing (>= 3.0): {passing}/{len(eval_prompts)} ({passing/len(eval_prompts)*100:.0f}%)\")\nprint(f\"Verdict: {'PASS' if avg_reward >= 2.5 else 'NEEDS MORE TRAINING'}\")\n\ndel grpo_model, base_model\ntorch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Merge LoRA + Convert to GGUF ──\n\n# Merge on CPU to save GPU memory\nprint(\"Merging LoRA adapter into base model (CPU)...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME, torch_dtype=torch.float16, device_map=\"cpu\", trust_remote_code=True,\n)\nmerged = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\nmerged = merged.merge_and_unload()\n\nos.makedirs(MERGED_DIR, exist_ok=True)\nmerged.save_pretrained(MERGED_DIR)\ntokenizer.save_pretrained(MERGED_DIR)\nprint(f\"Merged model saved to {MERGED_DIR}\")\n\ndel merged, base_model\ntorch.cuda.empty_cache()\ngc.collect()\n\n# ── Convert to GGUF ──\nos.makedirs(GGUF_DIR, exist_ok=True)\nLLAMA_CPP = \"/kaggle/working/llama.cpp\"\n\nif not os.path.exists(LLAMA_CPP):\n    !git clone --depth 1 https://github.com/ggml-org/llama.cpp {LLAMA_CPP}\n\n!pip install -q gguf numpy sentencepiece\n\nfp16_gguf = os.path.join(GGUF_DIR, \"octo-llm-f16.gguf\")\nprint(\"\\nConverting to FP16 GGUF...\")\n!python {LLAMA_CPP}/convert_hf_to_gguf.py {MERGED_DIR} --outfile {fp16_gguf} --outtype f16\nassert os.path.exists(fp16_gguf), \"FP16 conversion failed\"\nprint(f\"FP16 GGUF: {os.path.getsize(fp16_gguf)/1024**3:.2f} GB\")\n\n# Build quantize tool\nprint(\"\\nBuilding llama-quantize...\")\n!cd {LLAMA_CPP} && cmake -B build -DCMAKE_BUILD_TYPE=Release 2>&1 | tail -3\n!cd {LLAMA_CPP} && cmake --build build --target llama-quantize -j$(nproc) 2>&1 | tail -5\n\nimport subprocess\nresult = subprocess.run(\n    [\"find\", LLAMA_CPP + \"/build\", \"-name\", \"llama-quantize\", \"-type\", \"f\"],\n    capture_output=True, text=True,\n)\nquantize_bin = result.stdout.strip().split(\"\\n\")[0]\nassert quantize_bin and os.path.exists(quantize_bin), f\"llama-quantize not found\"\nprint(f\"quantize binary: {quantize_bin}\")\n\n# Q5_K_M — matches base model quality (recommended for OctoFlow chat)\nq5_gguf = os.path.join(GGUF_DIR, \"octo-llm-v0.2-Q5_K_M.gguf\")\nprint(f\"\\nQuantizing to Q5_K_M...\")\n!{quantize_bin} {fp16_gguf} {q5_gguf} Q5_K_M\nassert os.path.exists(q5_gguf), \"Q5_K_M quantization failed\"\n\n# Q4_K_M — smaller alternative\nq4_gguf = os.path.join(GGUF_DIR, \"octo-llm-v0.2-Q4_K_M.gguf\")\nprint(f\"Quantizing to Q4_K_M...\")\n!{quantize_bin} {fp16_gguf} {q4_gguf} Q4_K_M\nassert os.path.exists(q4_gguf), \"Q4_K_M quantization failed\"\n\nfp16_sz = os.path.getsize(fp16_gguf) / 1024**3\nq5_sz = os.path.getsize(q5_gguf) / 1024**3\nq4_sz = os.path.getsize(q4_gguf) / 1024**3\nprint(f\"\\nFP16:    {fp16_sz:.2f} GB\")\nprint(f\"Q5_K_M:  {q5_sz:.2f} GB ({q5_sz/fp16_sz*100:.0f}%)\")\nprint(f\"Q4_K_M:  {q4_sz:.2f} GB ({q4_sz/fp16_sz*100:.0f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Done ──\nprint(\"=\" * 60)\nprint(\"octo-llm GRPO Training Complete!\")\nprint(\"=\" * 60)\nprint(f\"\\nMethod: GRPO (compiler-as-reward-model)\")\nprint(f\"Base model: {MODEL_NAME}\")\nprint(f\"Prompts: {NUM_PROMPTS} ({NUM_PROMPTS - len(CHAIN_PROMPTS)} from bank + {len(CHAIN_PROMPTS)} chain)\")\nprint(f\"Generations: {NUM_GENERATIONS} per prompt\")\nprint(f\"Reward: Python OctoFlow syntax checker (max {MAX_REWARD})\")\nprint()\n\nfor name, path in {\n    \"GRPO Adapter\": ADAPTER_DIR,\n    \"Merged Model\": MERGED_DIR,\n    \"FP16 GGUF\": os.path.join(GGUF_DIR, \"octo-llm-f16.gguf\"),\n    \"Q5_K_M GGUF\": os.path.join(GGUF_DIR, \"octo-llm-v0.2-Q5_K_M.gguf\"),\n    \"Q4_K_M GGUF\": os.path.join(GGUF_DIR, \"octo-llm-v0.2-Q4_K_M.gguf\"),\n}.items():\n    if os.path.exists(path):\n        if os.path.isdir(path):\n            sz = sum(os.path.getsize(os.path.join(d, f))\n                     for d, _, fns in os.walk(path) for f in fns)\n        else:\n            sz = os.path.getsize(path)\n        print(f\"  {name}: {sz/1024**2:.1f} MB\")\n    else:\n        print(f\"  {name}: MISSING\")\n\nprint(f\"\\nNext steps:\")\nprint(f\"  1. Download octo-llm-v0.2-Q5_K_M.gguf\")\nprint(f\"  2. Copy to C:\\\\OctoFlow\\\\models\\\\octo-llm-v0.2.gguf\")\nprint(f\"  3. Test: octoflow chat --model models/octo-llm-v0.2.gguf\")\nprint(f\"  4. Run M9 validation: OctoFlowBench Pass@1 (base vs GRPO-trained)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}